"""åˆ†æå·¥å…· - è®© Agent å…·å¤‡æ–‡æ¡£åˆ†æå’Œæ€»ç»“èƒ½åŠ›"""

from typing import List, Dict, Any, Optional
from pathlib import Path

from src.agent.tools.base import BaseTool, ToolResult, ToolCategory
from src.config.settings import Config


class DocumentAnalysisTool(BaseTool):
    """æ–‡æ¡£ç»“æ„åˆ†æå·¥å…·
    
    åˆ†æçŸ¥è¯†åº“çš„æ–‡æ¡£ç»“æ„ï¼Œæä¾›ä¼˜åŒ–å»ºè®®
    """
    
    def __init__(self, documents_path: str = None):
        self._documents_path = documents_path or "./documents"
        super().__init__()
    
    @property
    def name(self) -> str:
        return "analyze_documents"
    
    @property
    def description(self) -> str:
        return "åˆ†æçŸ¥è¯†åº“æ–‡æ¡£çš„ç»“æ„å’Œç»„ç»‡æ–¹å¼ï¼Œè¯†åˆ«é—®é¢˜å¹¶æä¾›ä¼˜åŒ–å»ºè®®ã€‚"
    
    @property
    def category(self) -> ToolCategory:
        return ToolCategory.ANALYSIS
    
    @property
    def parameters(self) -> List[Dict[str, Any]]:
        return [
            {
                "name": "analysis_type",
                "type": "string",
                "description": "åˆ†æç±»å‹: 'structure'(ç›®å½•ç»“æ„), 'content'(å†…å®¹è´¨é‡), 'coverage'(è¦†ç›–åº¦), 'all'(å…¨éƒ¨)ï¼Œé»˜è®¤ 'structure'",
                "required": False
            }
        ]
    
    def _analyze_structure(self, docs_path: Path) -> Dict[str, Any]:
        """åˆ†æç›®å½•ç»“æ„"""
        analysis = {
            "total_files": 0,
            "total_dirs": 0,
            "file_types": {},
            "depth_distribution": {},
            "issues": [],
            "suggestions": []
        }
        
        # éå†æ–‡æ¡£ç›®å½•
        for item in docs_path.rglob("*"):
            if item.is_file():
                analysis["total_files"] += 1
                
                # ç»Ÿè®¡æ–‡ä»¶ç±»å‹
                ext = item.suffix.lower()
                analysis["file_types"][ext] = analysis["file_types"].get(ext, 0) + 1
                
                # ç»Ÿè®¡ç›®å½•æ·±åº¦
                depth = len(item.relative_to(docs_path).parts) - 1
                analysis["depth_distribution"][depth] = analysis["depth_distribution"].get(depth, 0) + 1
                
            elif item.is_dir():
                analysis["total_dirs"] += 1
        
        # è¯†åˆ«é—®é¢˜
        if analysis["total_dirs"] == 0 and analysis["total_files"] > 5:
            analysis["issues"].append("æ‰€æœ‰æ–‡ä»¶éƒ½åœ¨æ ¹ç›®å½•ï¼Œç¼ºä¹åˆ†ç±»ç»„ç»‡")
            analysis["suggestions"].append("å»ºè®®æŒ‰ä¸»é¢˜åˆ›å»ºå­ç›®å½•ï¼Œå¦‚: 'tutorials/', 'api-docs/', 'faq/'")
        
        if len(analysis["file_types"]) == 1:
            analysis["issues"].append(f"æ‰€æœ‰æ–‡æ¡£éƒ½æ˜¯åŒä¸€æ ¼å¼ ({list(analysis['file_types'].keys())[0]})")
            analysis["suggestions"].append("è€ƒè™‘ä½¿ç”¨ Markdown æ ¼å¼ä»¥è·å¾—æ›´å¥½çš„å¯è¯»æ€§å’Œç»“æ„åŒ–")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ README
        readme_exists = any(
            f.name.lower() in ['readme.md', 'readme.txt', 'index.md']
            for f in docs_path.iterdir() if f.is_file()
        )
        if not readme_exists:
            analysis["issues"].append("ç¼ºå°‘ README æˆ–ç´¢å¼•æ–‡ä»¶")
            analysis["suggestions"].append("åˆ›å»º README.md ä½œä¸ºçŸ¥è¯†åº“çš„å…¥å£å’Œå¯¼èˆª")
        
        return analysis
    
    def _analyze_content(self, docs_path: Path) -> Dict[str, Any]:
        """åˆ†æå†…å®¹è´¨é‡"""
        analysis = {
            "documents": [],
            "avg_length": 0,
            "issues": [],
            "suggestions": []
        }
        
        total_length = 0
        short_docs = []
        
        for file_path in docs_path.rglob("*"):
            if file_path.is_file() and file_path.suffix.lower() in {'.txt', '.md'}:
                try:
                    content = file_path.read_text(encoding='utf-8')
                    length = len(content)
                    total_length += length
                    
                    doc_info = {
                        "name": file_path.name,
                        "path": str(file_path.relative_to(docs_path)),
                        "length": length,
                        "has_headings": '#' in content if file_path.suffix == '.md' else False,
                        "has_code_blocks": '```' in content
                    }
                    analysis["documents"].append(doc_info)
                    
                    if length < 200:
                        short_docs.append(file_path.name)
                        
                except Exception:
                    pass
        
        if analysis["documents"]:
            analysis["avg_length"] = total_length // len(analysis["documents"])
        
        if short_docs:
            analysis["issues"].append(f"ä»¥ä¸‹æ–‡æ¡£å†…å®¹è¿‡çŸ­: {', '.join(short_docs[:5])}")
            analysis["suggestions"].append("è€ƒè™‘åˆå¹¶ç›¸å…³çš„çŸ­æ–‡æ¡£æˆ–æ‰©å……å†…å®¹")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ–‡æ¡£ç¼ºå°‘æ ‡é¢˜ç»“æ„
        no_headings = [d["name"] for d in analysis["documents"] if not d["has_headings"]]
        if no_headings and len(no_headings) > len(analysis["documents"]) / 2:
            analysis["issues"].append("å¤§éƒ¨åˆ† Markdown æ–‡æ¡£ç¼ºå°‘æ ‡é¢˜ç»“æ„")
            analysis["suggestions"].append("ä½¿ç”¨ # æ ‡é¢˜æ¥ç»„ç»‡æ–‡æ¡£ç»“æ„ï¼Œæœ‰åŠ©äº RAG æ£€ç´¢")
        
        return analysis
    
    def execute(self, **kwargs) -> ToolResult:
        """æ‰§è¡Œæ–‡æ¡£åˆ†æ"""
        analysis_type = kwargs.get("analysis_type", "structure")
        
        try:
            docs_path = Path(self._documents_path)
            
            if not docs_path.exists():
                return ToolResult(
                    success=False,
                    output="",
                    error=f"æ–‡æ¡£ç›®å½•ä¸å­˜åœ¨: {self._documents_path}"
                )
            
            results = {}
            output_parts = ["# çŸ¥è¯†åº“æ–‡æ¡£åˆ†ææŠ¥å‘Š\n"]
            
            if analysis_type in ["structure", "all"]:
                structure = self._analyze_structure(docs_path)
                results["structure"] = structure
                
                output_parts.append("## ğŸ“‚ ç›®å½•ç»“æ„åˆ†æ")
                output_parts.append(f"- æ–‡ä»¶æ€»æ•°: {structure['total_files']}")
                output_parts.append(f"- ç›®å½•æ€»æ•°: {structure['total_dirs']}")
                output_parts.append(f"- æ–‡ä»¶ç±»å‹: {structure['file_types']}")
                
                if structure["issues"]:
                    output_parts.append("\n**å‘ç°çš„é—®é¢˜:**")
                    for issue in structure["issues"]:
                        output_parts.append(f"  âš ï¸ {issue}")
                
                if structure["suggestions"]:
                    output_parts.append("\n**ä¼˜åŒ–å»ºè®®:**")
                    for sug in structure["suggestions"]:
                        output_parts.append(f"  ğŸ’¡ {sug}")
                output_parts.append("")
            
            if analysis_type in ["content", "all"]:
                content = self._analyze_content(docs_path)
                results["content"] = content
                
                output_parts.append("## ğŸ“ å†…å®¹è´¨é‡åˆ†æ")
                output_parts.append(f"- æ–‡æ¡£æ•°é‡: {len(content['documents'])}")
                output_parts.append(f"- å¹³å‡é•¿åº¦: {content['avg_length']} å­—ç¬¦")
                
                if content["issues"]:
                    output_parts.append("\n**å‘ç°çš„é—®é¢˜:**")
                    for issue in content["issues"]:
                        output_parts.append(f"  âš ï¸ {issue}")
                
                if content["suggestions"]:
                    output_parts.append("\n**ä¼˜åŒ–å»ºè®®:**")
                    for sug in content["suggestions"]:
                        output_parts.append(f"  ğŸ’¡ {sug}")
            
            return ToolResult(
                success=True,
                output="\n".join(output_parts),
                data=results,
                metadata={"analysis_type": analysis_type}
            )
            
        except Exception as e:
            return ToolResult(success=False, output="", error=f"åˆ†æå¤±è´¥: {str(e)}")


class SummarizeTool(BaseTool):
    """æ–‡æœ¬æ€»ç»“å·¥å…·"""
    
    def __init__(self):
        self._llm = None
        super().__init__()
    
    def _init_llm(self):
        """åˆå§‹åŒ– LLM"""
        if self._llm is None:
            if Config.MODEL_PROVIDER == "ollama":
                from langchain_community.llms import Ollama
                self._llm = Ollama(
                    base_url=Config.OLLAMA_API_URL,
                    model=Config.LLM_MODEL,
                    temperature=0.3,
                )
            else:
                from langchain.chat_models import init_chat_model
                self._llm = init_chat_model(
                    Config.LLM_MODEL,
                    temperature=0.3,
                )
        return self._llm
    
    @property
    def name(self) -> str:
        return "summarize"
    
    @property
    def description(self) -> str:
        return "æ€»ç»“é•¿æ–‡æœ¬æˆ–å¤šä¸ªæ–‡æ¡£çš„å†…å®¹ï¼Œç”Ÿæˆç®€æ´çš„æ‘˜è¦ã€‚"
    
    @property
    def category(self) -> ToolCategory:
        return ToolCategory.ANALYSIS
    
    @property
    def parameters(self) -> List[Dict[str, Any]]:
        return [
            {
                "name": "text",
                "type": "string",
                "description": "è¦æ€»ç»“çš„æ–‡æœ¬å†…å®¹",
                "required": True
            },
            {
                "name": "style",
                "type": "string",
                "description": "æ€»ç»“é£æ ¼: 'brief'(ç®€çŸ­), 'detailed'(è¯¦ç»†), 'bullet'(è¦ç‚¹åˆ—è¡¨)ï¼Œé»˜è®¤ 'brief'",
                "required": False
            },
            {
                "name": "max_length",
                "type": "integer",
                "description": "æ‘˜è¦æœ€å¤§é•¿åº¦ï¼ˆå­—æ•°ï¼‰ï¼Œé»˜è®¤ 200",
                "required": False
            }
        ]
    
    def execute(self, **kwargs) -> ToolResult:
        """æ‰§è¡Œæ–‡æœ¬æ€»ç»“"""
        text = kwargs.get("text", "")
        style = kwargs.get("style", "brief")
        max_length = kwargs.get("max_length", 200)
        
        if not text:
            return ToolResult(success=False, output="", error="æ–‡æœ¬å†…å®¹ä¸èƒ½ä¸ºç©º")
        
        if len(text) < 100:
            return ToolResult(
                success=True,
                output=f"æ–‡æœ¬è¾ƒçŸ­ï¼Œæ— éœ€æ€»ç»“:\n{text}",
                data={"summary": text, "original_length": len(text)}
            )
        
        try:
            llm = self._init_llm()
            
            style_instructions = {
                "brief": f"è¯·ç”¨ä¸è¶…è¿‡{max_length}å­—æ€»ç»“ä»¥ä¸‹å†…å®¹ï¼Œåªä¿ç•™æœ€æ ¸å¿ƒçš„ä¿¡æ¯ï¼š",
                "detailed": f"è¯·è¯¦ç»†æ€»ç»“ä»¥ä¸‹å†…å®¹ï¼ŒåŒ…å«ä¸»è¦è§‚ç‚¹å’Œå…³é”®ç»†èŠ‚ï¼ˆä¸è¶…è¿‡{max_length * 2}å­—ï¼‰ï¼š",
                "bullet": f"è¯·ç”¨è¦ç‚¹åˆ—è¡¨çš„å½¢å¼æ€»ç»“ä»¥ä¸‹å†…å®¹çš„å…³é”®ç‚¹ï¼ˆä¸è¶…è¿‡{max_length}å­—ï¼‰ï¼š"
            }
            
            prompt = f"""{style_instructions.get(style, style_instructions['brief'])}

{text}

æ€»ç»“ï¼š"""
            
            response = llm.invoke(prompt)
            summary = response if isinstance(response, str) else (
                response.content if hasattr(response, 'content') else str(response)
            )
            
            return ToolResult(
                success=True,
                output=f"**æ‘˜è¦** ({style} é£æ ¼):\n\n{summary.strip()}",
                data={
                    "summary": summary.strip(),
                    "original_length": len(text),
                    "summary_length": len(summary)
                },
                metadata={"style": style}
            )
            
        except Exception as e:
            return ToolResult(success=False, output="", error=f"æ€»ç»“å¤±è´¥: {str(e)}")


class GenerateReportTool(BaseTool):
    """ç”ŸæˆæŠ¥å‘Šå·¥å…·"""
    
    def __init__(self):
        self._llm = None
        super().__init__()
    
    def _init_llm(self):
        if self._llm is None:
            if Config.MODEL_PROVIDER == "ollama":
                from langchain_community.llms import Ollama
                self._llm = Ollama(
                    base_url=Config.OLLAMA_API_URL,
                    model=Config.LLM_MODEL,
                    temperature=0.5,
                )
            else:
                from langchain.chat_models import init_chat_model
                self._llm = init_chat_model(Config.LLM_MODEL, temperature=0.5)
        return self._llm
    
    @property
    def name(self) -> str:
        return "generate_report"
    
    @property
    def description(self) -> str:
        return "æ ¹æ®æ”¶é›†çš„ä¿¡æ¯ç”Ÿæˆç»“æ„åŒ–æŠ¥å‘Šï¼Œæ”¯æŒå¤šç§æ ¼å¼ã€‚"
    
    @property
    def category(self) -> ToolCategory:
        return ToolCategory.ANALYSIS
    
    @property
    def parameters(self) -> List[Dict[str, Any]]:
        return [
            {
                "name": "topic",
                "type": "string",
                "description": "æŠ¥å‘Šä¸»é¢˜",
                "required": True
            },
            {
                "name": "content",
                "type": "string",
                "description": "æŠ¥å‘Šå†…å®¹æ¥æºï¼ˆå¯ä»¥æ˜¯å¤šæ®µæ–‡æœ¬ï¼‰",
                "required": True
            },
            {
                "name": "format",
                "type": "string",
                "description": "æŠ¥å‘Šæ ¼å¼: 'markdown', 'plain', 'html'ï¼Œé»˜è®¤ 'markdown'",
                "required": False
            }
        ]
    
    def execute(self, **kwargs) -> ToolResult:
        """ç”ŸæˆæŠ¥å‘Š"""
        topic = kwargs.get("topic", "")
        content = kwargs.get("content", "")
        report_format = kwargs.get("format", "markdown")
        
        if not topic or not content:
            return ToolResult(success=False, output="", error="ä¸»é¢˜å’Œå†…å®¹ä¸èƒ½ä¸ºç©º")
        
        try:
            llm = self._init_llm()
            
            format_instructions = {
                "markdown": "ä½¿ç”¨ Markdown æ ¼å¼ï¼ŒåŒ…å«æ ‡é¢˜ã€åˆ—è¡¨ã€ä»£ç å—ç­‰",
                "plain": "ä½¿ç”¨çº¯æ–‡æœ¬æ ¼å¼ï¼Œç»“æ„æ¸…æ™°",
                "html": "ä½¿ç”¨ HTML æ ¼å¼ï¼ŒåŒ…å«é€‚å½“çš„æ ‡ç­¾"
            }
            
            prompt = f"""è¯·æ ¹æ®ä»¥ä¸‹å†…å®¹ï¼Œç”Ÿæˆä¸€ä»½å…³äº"{topic}"çš„ä¸“ä¸šæŠ¥å‘Šã€‚

{format_instructions.get(report_format, format_instructions['markdown'])}

åŸå§‹å†…å®¹ï¼š
{content}

è¦æ±‚ï¼š
1. åŒ…å«æ‘˜è¦ã€æ­£æ–‡ã€ç»“è®º
2. é€»è¾‘æ¸…æ™°ï¼Œå±‚æ¬¡åˆ†æ˜
3. çªå‡ºå…³é”®ä¿¡æ¯
4. è¯­è¨€ä¸“ä¸šç®€æ´

è¯·ç”ŸæˆæŠ¥å‘Šï¼š"""
            
            response = llm.invoke(prompt)
            report = response if isinstance(response, str) else (
                response.content if hasattr(response, 'content') else str(response)
            )
            
            return ToolResult(
                success=True,
                output=report.strip(),
                data={
                    "topic": topic,
                    "report": report.strip(),
                    "format": report_format
                },
                metadata={"format": report_format}
            )
            
        except Exception as e:
            return ToolResult(success=False, output="", error=f"ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {str(e)}")
