# é—®é¢˜æ’æŸ¥å’Œä¿®å¤æŠ¥å‘Š

## æ‚¨é‡åˆ°çš„é—®é¢˜ âŒ

åœ¨å‰ç«¯é…ç½®ä¸­é€‰æ‹© Ollama æ¨¡å‹åï¼Œå‘é€é—®é¢˜æ—¶ï¼š
- âœ— **åªæ˜¾ç¤ºå‚è€ƒæ¥æº**
- âœ— **æ²¡æœ‰æ˜¾ç¤º AI çš„å›å¤å†…å®¹**

---

## é—®é¢˜æ ¹æºåˆ†æ ğŸ”

### ç¬¬ä¸€ä¸ªé—®é¢˜ï¼šollama_client.py çš„ç”Ÿæˆå™¨é™·é˜±

**ä½ç½®**: [ollama_client.py](ollama_client.py)

åŸå§‹ä»£ç åœ¨åŒä¸€ä¸ªå‡½æ•°ä¸­æ··åˆäº† `yield` å’Œ `return`ï¼š
```python
def generate(..., stream: bool = False):
    # ...
    if stream:
        yield something  # â† æœ‰ yield
        return result
    else:
        return response_text  # â† æ—  yieldï¼Œåº”è¯¥è¿”å›å­—ç¬¦ä¸²
```

**ä¸ºä»€ä¹ˆè¿™æ˜¯ä¸ªé—®é¢˜ï¼Ÿ**

Python ä¼šå°†**ä»»ä½•åŒ…å« `yield` çš„å‡½æ•°**æ ‡è®°ä¸º**ç”Ÿæˆå™¨å‡½æ•°**ï¼Œå³ä½¿ `yield` åœ¨æ¡ä»¶åˆ†æ”¯ä¸­ã€‚è¿™æ„å‘³ç€ï¼š
- æ— è®º `stream` å€¼æ˜¯å¤šå°‘ï¼Œ`generate()` éƒ½ä¼šè¿”å›ä¸€ä¸ª**ç”Ÿæˆå™¨å¯¹è±¡** 
- è€Œä¸æ˜¯æœŸæœ›çš„**å­—ç¬¦ä¸²**

**å½±å“**: å½“ `stream=False` æ—¶ï¼ˆAPI ä¸­çš„æƒ…å†µï¼‰ï¼Œå‡½æ•°è¿”å›ç”Ÿæˆå™¨è€Œä¸æ˜¯å­—ç¬¦ä¸²ã€‚

### ç¬¬äºŒä¸ªé—®é¢˜ï¼šapp_api.py çš„æ•°æ®æµä¸­æ–­

**ä½ç½®**: [app_api.py](app_api.py#L249-L261)

ä»£ç å°è¯•é€å­—ç¬¦è¿­ä»£ `ollama_result`ï¼š
```python
ollama_result = ollama_generate(...)  # è¿”å›ç”Ÿæˆå™¨å¯¹è±¡ï¼ˆé”™è¯¯ï¼ï¼‰

for char in ollama_result:  # è¿­ä»£ç”Ÿæˆå™¨å¯¹è±¡
    yield f"data: {json.dumps({'type': 'content', 'data': char})}\n\n"
```

**é—®é¢˜**: è¿­ä»£ç”Ÿæˆå™¨å¯¹è±¡ä¸ä¼šå¾—åˆ°å­—ç¬¦ï¼Œå¯¼è‡´ `content` ç±»å‹çš„æ•°æ®**ä»æœªè¢«å‘é€**ã€‚

---

## è§£å†³æ–¹æ¡ˆ âœ…

### ä¿®å¤æ­¥éª¤

#### 1. [ollama_client.py](ollama_client.py) - åˆ†ç¦»å‡½æ•°é€»è¾‘

å°†ä¸€ä¸ªå‡½æ•°æ‹†åˆ†ä¸ºä¸‰ä¸ªå‡½æ•°ï¼š

```python
# ä¸»å‡½æ•°ï¼šé€‰æ‹©æ‰§è¡Œå“ªä¸ªåˆ†æ”¯
def generate(..., stream: bool = False):
    # ...
    if stream:
        return _generate_stream(resp)      # è¿”å›ç”Ÿæˆå™¨
    else:
        return _generate_non_stream(resp)  # è¿”å›å­—ç¬¦ä¸²

# æµå¼å¤„ç†ï¼šä½¿ç”¨ yield
def _generate_stream(resp):
    try:
        for line in resp.iter_lines():
            if line:
                chunk = json.loads(line)
                if "response" in chunk:
                    yield chunk["response"]  # è¿™é‡Œæœ‰ yield æ˜¯åˆç†çš„
    except json.JSONDecodeError as e:
        raise OllamaError(f"è§£æ Ollama å“åº”å¤±è´¥: {e}")

# éæµå¼å¤„ç†ï¼šè¿”å›å­—ç¬¦ä¸²
def _generate_non_stream(resp) -> str:  # â† æ˜ç¡®è¿”å›å­—ç¬¦ä¸²
    try:
        data = resp.json()
        # ... JSON å¤„ç†é€»è¾‘ä¿æŒä¸å˜ ...
        return response_text  # ç›´æ¥è¿”å›å­—ç¬¦ä¸²
    except json.JSONDecodeError as e:
        raise OllamaError(f"è§£æ Ollama å“åº”å¤±è´¥: {e}")
```

**ä¼˜ç‚¹**:
- âœ… `_generate_non_stream()` ä¸åŒ…å« `yield`ï¼Œæ€»æ˜¯è¿”å›å­—ç¬¦ä¸²
- âœ… `_generate_stream()` ä¸“é—¨å¤„ç†æµå¼é€»è¾‘
- âœ… `generate()` æ˜ç¡®æŒ‡å®šè¿”å›ç±»å‹

#### 2. [app_api.py](app_api.py#L249-L261) - ç®€åŒ–å¤„ç†

ç°åœ¨ `ollama_generate()` æ€»æ˜¯è¿”å›å­—ç¬¦ä¸²ï¼Œæ‰€ä»¥å¤„ç†å˜å¾—ç®€å•ï¼š

```python
# è°ƒç”¨ Ollama ç”Ÿæˆ
ollama_result = ollama_generate(
    model=model_name,
    prompt=prompt,
    max_tokens=Config.MAX_TOKENS,
    temperature=Config.TEMPERATURE,
    api_url=api_url,
    stream=False
)

# é€å­—ç¬¦å‘é€å†…å®¹ï¼ˆç°åœ¨ ollama_result æ˜¯å­—ç¬¦ä¸²ï¼‰
if ollama_result:
    for char in ollama_result:
        yield f"data: {json.dumps({'type': 'content', 'data': char})}\n\n"
        await asyncio.sleep(0.01)

yield f"data: {json.dumps({'type': 'done'})}\n\n"
```

---

## ä¿®å¤éªŒè¯ âœ”ï¸

ä¿®å¤åçš„æ•°æ®æµç¤ºä¾‹ï¼š

**ä¿®å¤å‰**ï¼ˆç¼ºå°‘å†…å®¹ï¼‰ï¼š
```
data: {"type": "sources", "data": [{"source": "...", "preview": "..."}]}

data: {"type": "done"}
```

**ä¿®å¤å**ï¼ˆå®Œæ•´æµï¼‰ï¼š
```
data: {"type": "sources", "data": [{"source": "...", "preview": "..."}]}

data: {"type": "content", "data": "1"}
data: {"type": "content", "data": "+"}
data: {"type": "content", "data": "1"}
data: {"type": "content", "data": "="}
data: {"type": "content", "data": "2"}

data: {"type": "done"}
```

å‰ç«¯ç°åœ¨å¯ä»¥æ¥æ”¶å¹¶æ˜¾ç¤ºæ‰€æœ‰å†…å®¹ã€‚

---

## æ€»ç»“

| ç—‡çŠ¶ | åŸå›  | è§£å†³æ–¹æ¡ˆ |
|------|------|---------|
| ç¼ºå°‘ AI å›å¤ | `generate()` è¿”å›ç”Ÿæˆå™¨è€Œéå­—ç¬¦ä¸² | æ‹†åˆ†ä¸º `_generate_stream()` å’Œ `_generate_non_stream()` |
| æ— æ³•é€å­—æ˜¾ç¤º | ç”Ÿæˆå™¨æ— æ³•è¢«å­—ç¬¦ä¸²è¿­ä»£ | ç¡®ä¿ `_generate_non_stream()` è¿”å›çœŸå®å­—ç¬¦ä¸² |

### ä¿®æ”¹æ–‡ä»¶
- âœ… **ollama_client.py** - å®Œå…¨é‡æ„
- âœ… **app_api.py** - ç®€åŒ– Ollama ç»“æœå¤„ç†

ç°åœ¨æ‚¨åº”è¯¥èƒ½çœ‹åˆ°ï¼š
- âœ… AI çš„å®Œæ•´å›å¤
- âœ… å‚è€ƒæ¥æº
- âœ… é€å­—æ˜¾ç¤ºæ•ˆæœ

